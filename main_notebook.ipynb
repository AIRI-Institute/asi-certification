{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import warnings\n",
    "from time import time\n",
    "import datetime\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from smooth import divide_batch, Smooth\n",
    "from parser_certify import get_parser\n",
    "from our_utils import Producer, CustomModel, predict_with_radius, predict_with_radius_2, predict_with_radius_3\n",
    "from our_utils import ERA_of_f, ERA_of_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_parser().parse_args([])\n",
    "args.dataset = \"VoxCeleb2\"\n",
    "args.dataset_train = None\n",
    "args.dataset_test = ... # path to dataset\n",
    "# args.outdur = ... # path to save results\n",
    "args.num_support_val = 5\n",
    "args.classes_per_it_val = 118  # 1118, 7363 \n",
    "args.sigma = 0.01\n",
    "args.N = 20000\n",
    "\n",
    "args.K = 5\n",
    "\n",
    "\n",
    "args.normalize1=True\n",
    "args.normalize_enrlollment_prototypes=True\n",
    "\n",
    "args.cuda_number = 0\n",
    "device = 'cuda:{n}'.format(n=args.cuda_number) if torch.cuda.is_available() and args.cuda else 'cpu'\n",
    "args.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_name = \"ecapa-tdnn\"\n",
    "args.emb_size = 192\n",
    "\n",
    "# args.model_name = \"pyannote\"\n",
    "# args.emb_size = 512\n",
    "\n",
    "# args.model_name = \"wavlm\"\n",
    "# args.emb_size = 512\n",
    "\n",
    "# args.model_name = \"campplus\"\n",
    "# args.emb_size = 192\n",
    "\n",
    "# args.model_name = \"eres2net\"\n",
    "# args.emb_size = 192\n",
    "\n",
    "# args.model_name = \"wespeaker\"\n",
    "# args.emb_size = 256\n",
    "\n",
    "model = CustomModel(args)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = Producer(model, args, args.normalize_enrlollment_prototypes)\n",
    "class_prototypes, speaker_enrollment_audios, speaker_inference_audios, id2class, class2id = pr.produce_subsets()\n",
    "\n",
    "class_prototypes_list = torch.stack(list(class_prototypes.values()))\n",
    "centroids = class_prototypes_list.squeeze(1).to(device)\n",
    "\n",
    "smoothed_model = Smooth(\n",
    "    base_model=model,\n",
    "    device=device,\n",
    "    num_classes=args.classes_per_it_val,\n",
    "    sigma=args.sigma,\n",
    "    alpha=args.alpha,\n",
    "    mode=args.mode,\n",
    "    normalize1=args.normalize1,\n",
    "    emb_size=model.emb_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_delta = 2\n",
    "n_grid = 10\n",
    "batch_size = 8\n",
    "results_f, results2_f, era_f = ERA_of_f(model, pr, device, max_delta, n_grid=n_grid, batch_size=batch_size, attack='pgd')\n",
    "\n",
    "plt.plot(np.linspace(0, max_delta, n_grid), results2_f.mean(dim=0))\n",
    "\n",
    "plt.ylabel('Empirical robust accuracy (f)')\n",
    "plt.xlabel('Attack radius')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_delta = 2\n",
    "n_grid = 10\n",
    "batch_size = 8\n",
    "\n",
    "results_g, results2_g, era_g = ERA_of_g(model=model, \n",
    "                                        smoothed_model=smoothed_model,\n",
    "                                        args=args,\n",
    "                                        producer=pr,\n",
    "                                        device=device, \n",
    "                                        delta_max=max_delta,\n",
    "                                        n_grid=10)\n",
    "\n",
    "plt.plot(np.linspace(0, max_delta, n_grid), results2_g.mean(dim=0))\n",
    "\n",
    "plt.ylabel('Empirical robust accuracy (g)')\n",
    "plt.xlabel('Attack radius')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_len = 3\n",
    "\n",
    "y = []\n",
    "\n",
    "sum_audios = 0\n",
    "correct = 0\n",
    "\n",
    "preds = []\n",
    "preds_cohen = []\n",
    "\n",
    "radii = []\n",
    "new_radii = []\n",
    "radii_cohen = []\n",
    "\n",
    "correct_or_not = []\n",
    "correct_or_not_cohen = []\n",
    "for speaker_id in tqdm(pr.speakers_test_only, total=len(pr.speakers_test_only)):\n",
    "    pathes = speaker_inference_audios[speaker_id]\n",
    "    gt_class = id2class[speaker_id]\n",
    "    wavs_paths = speaker_inference_audios[class2id[gt_class]]\n",
    "    wav_path = wavs_paths[np.random.choice(len(wavs_paths))]\n",
    "\n",
    "    sample = torchaudio.load(wav_path)[0][0, :audio_len*16000].to(\"cuda:3\")\n",
    "    sum_audios += 1\n",
    "    pred_class, gamma_lcb, radius, time_elapsed, n_samples, radius_as_in_article, pred_centroid, adv_centroid = predict_with_radius(\n",
    "        args,\n",
    "        smoothed_model,\n",
    "        sample=sample,\n",
    "        centroids=centroids,\n",
    "        centroid_target=torch.arange(args.classes_per_it_val)\n",
    "        )\n",
    "    \n",
    "    pred_class_cohen, radius_cohen = predict_with_radius_2(args, model, sample, centroids, centroid_target=torch.arange(args.classes_per_it_val))\n",
    "\n",
    "    radius_as_in_article = torch.tensor(radius_as_in_article)\n",
    "    print(f\"GT class: {gt_class}   |    Predicted class: {pred_class}   |    Predicted class RS: {pred_class_cohen}  |   Radius as in article: {radius_as_in_article}    |   New radius: {radius}|   Radius RS: {radius_cohen}\")\n",
    "\n",
    "    is_correct = int(pred_class == gt_class)\n",
    "    preds.append(pred_class)\n",
    "    preds_cohen.append(pred_class_cohen)\n",
    "    radii.append(radius_as_in_article)\n",
    "    new_radii.append(radius)\n",
    "    radii_cohen.append(radius_cohen)\n",
    "    if is_correct:\n",
    "        correct += 1\n",
    "    correct_or_not.append(is_correct)\n",
    "    correct_or_not_cohen.append(int(pred_class_cohen == gt_class))\n",
    "\n",
    "print(correct / sum_audios)\n",
    "preds = np.array(preds)\n",
    "preds_cohen = np.array(preds_cohen)\n",
    "radii = np.array(radii)\n",
    "new_radii = np.array(new_radii)\n",
    "radii_cohen = np.array(radii_cohen)\n",
    "correct_or_not = np.array(correct_or_not)\n",
    "correct_or_not_cohen = np.array(correct_or_not_cohen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_attack = np.linspace(0, 0.1, 100)\n",
    "\n",
    "cra_old_list = []\n",
    "cra_new_list = []\n",
    "cra_cohen_list = []\n",
    "for r in r_attack:\n",
    "    cra_old = np.mean((radii  >= r) * correct_or_not)\n",
    "    cra_new = np.mean((new_radii  >= r) * correct_or_not)\n",
    "    cra_cohen = np.mean((radii_cohen  >= r) * correct_or_not_cohen)\n",
    "    cra_old_list.append(cra_old)\n",
    "    cra_new_list.append(cra_new)\n",
    "    cra_cohen_list.append(cra_cohen)\n",
    "    \n",
    "    \n",
    "plt.plot(r_attack, cra_old_list, label=\"old_approach\")\n",
    "plt.plot(r_attack, cra_new_list, label=\"new_approach\")\n",
    "plt.plot(r_attack, cra_cohen_list, label=\"ordinary_rs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "sum_audios = 0\n",
    "correct = 0\n",
    "\n",
    "preds = []\n",
    "new_radii = []\n",
    "correct_or_not = []\n",
    "# for speaker_id, pathes in speaker_inference_audios.items():\n",
    "for speaker_id in tqdm(pr.speakers_test_only, total=len(pr.speakers_test_only)):\n",
    "    pathes = speaker_inference_audios[speaker_id]\n",
    "    gt_class = id2class[speaker_id]\n",
    "    wavs_paths = speaker_inference_audios[class2id[gt_class]]\n",
    "    wav_path = wavs_paths[np.random.choice(len(wavs_paths))]\n",
    "\n",
    "    sample = torchaudio.load(wav_path)[0][0, :3*16000].to(\"cuda:3\")\n",
    "    \n",
    "    sum_audios += 1\n",
    "    pred_class, radius = predict_with_radius_2(args, model, sample, centroids, centroid_target=torch.arange(args.classes_per_it_val))\n",
    "\n",
    "    print(f\"GT class: {gt_class}   |    Predicted class: {pred_class}   |   Radius: {radius}\")\n",
    "\n",
    "    is_correct = int(pred_class == gt_class)\n",
    "    preds.append(pred_class)\n",
    "    new_radii.append(radius)\n",
    "    if is_correct:\n",
    "        correct += 1\n",
    "    correct_or_not.append(is_correct)\n",
    "\n",
    "print(correct / sum_audios)\n",
    "preds = np.array(preds)\n",
    "new_radii = np.array(new_radii)\n",
    "correct_or_not = np.array(correct_or_not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_attack = np.linspace(0, 0.04, 100)\n",
    "\n",
    "cra_new_list = []\n",
    "for r in r_attack:\n",
    "    cra_new = np.mean((new_radii  >= r) * correct_or_not)\n",
    "    cra_new_list.append(cra_new)\n",
    "    \n",
    "\n",
    "plt.plot(r_attack, cra_new_list, label=\"other_approach\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
